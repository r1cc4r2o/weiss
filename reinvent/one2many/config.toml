version = 4
device = "cpu" # TOFIX
run_type = "staged_learning"
tb_logdir = "logs"
 
 
[[stage]]
termination = "simple"
max_steps = 1000
max_score = 1.0
chkpt_file = "final_agent.chkpt"
 
[stage.scoring]
type = "geometric_mean"

[[stage.scoring.component]]

[[stage.scoring.component.custom_alerts.endpoint]]
name = "Unwanted SMARTS"  # user chosen name for output
weight = 1.0  # weight to fine-tune the relevance of this component

# parameters for the component:
# a list of unwanted SMARTS(!) to be scored as zero
params.smarts = [
    "[*;r8]",
    "[*;r9]",
    "[*;r10]",
    "[*;r11]",
    "[*;r12]",
    "[*;r13]",
    "[*;r14]",
    "[*;r15]",
    "[*;r16]",
    "[*;r17]",
    "[#8][#8]",
    "[#6;+]",
    "[#16][#16]",
    "[#7;!n][S;!$(S(=O)=O)]",
    "[#7;!n][#7;!n]",
    "C#C",
    "C(=[O,S])[O,S]",
    "[#7;!n][C;!$(C(=[O,N])[N,O])][#16;!s]",
    "[#7;!n][C;!$(C(=[O,N])[N,O])][#7;!n]",
    "[#7;!n][C;!$(C(=[O,N])[N,O])][#8;!o]",
    "[#8;!o][C;!$(C(=[O,N])[N,O])][#16;!s]",
    "[#8;!o][C;!$(C(=[O,N])[N,O])][#8;!o]",
    "[#16;!s][C;!$(C(=[O,N])[N,O])][#16;!s]"
]



[[stage.scoring.component]]
[stage.scoring.component.QED]
[[stage.scoring.component.QED.endpoint]]
name = "QED"
weight = 1.0  # weight to fine-tune the importance of this component

transform.type = "sigmoid"
transform.high = 1.1
transform.low = -0.1
transform.k = 0.5


[[stage.scoring.component]]
[stage.scoring.component.TanimotoSimilarity]
[[stage.scoring.component.TanimotoSimilarity.endpoint]]
name = "TanimotoSimilarity"
weight = 1.0  # weight to fine-tune the importance of this component
params.smiles = [
   "MOLECULE_SMILES" # TOFIX
]
params.radius = 2
params.use_counts = true
params.use_features = false


[parameters]
use_checkpoint = true
purge_memories = true
agent_file = "path_to_agent_file" # TOFIX
prior_file = "path_to_prior_file" # TOFIX
batch_size = 32
smiles_file = "seed_smiles.smi"
unique_sequences = true
randomize_smiles = false
summary_csv_prefix = "smiles"
temperature = 0.1
sample_strategy = "multinomial"

[diversity_filter]
type = "PenalizeSameSmiles"
penalty_multiplier = 0.4

[learning_strategy]
type = "dap"
sigma = 64
rate = 0.00005

